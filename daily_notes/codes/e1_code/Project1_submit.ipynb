{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: pillow in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (7.0.0)\n"
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "# 필요한 라이브러리 가져오기\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/scissor_all\nscissor_all 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/rock_all\nrock_all 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/paper_all\npaper_all 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/scissor_test\nscissor_test 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/rock_test\nrock_test 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/paper_test\npaper_test 이미지 resize 완료!\n"
    }
   ],
   "source": [
    "\n",
    "def convertImageSize(name):\n",
    "    image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rcp_all/\"+name\n",
    "    print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "    images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "    img_size = 28\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(img_size,img_size)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img,\"JPEG\")\n",
    "\n",
    "    print(\"{} 이미지 resize 완료!\".format(name))\n",
    "\n",
    "dirs = ['scissor_all','rock_all','paper_all','scissor_test','rock_test','paper_test']\n",
    "for c in dirs:\n",
    "    convertImageSize(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전부 불러오고, ~~train/test 데이터 분리~~\n",
    "[데이터 분리 참조](https://rfriend.tistory.com/519)\n",
    "\n",
    "앞서 언급한대로, 분리는 진행하지 않고, 별도의 test 데이터( 슬랙에 올라온 다른 분의 데이터) 를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "all 이미지 개수는 6300 입니다.\nx_train shape: (6300, 28, 28, 3)\ny_train shape: (6300,)\ntest 이미지 개수는 300 입니다.\nx_test shape: (300, 28, 28, 3)\ny_test shape: (300,)\n"
    }
   ],
   "source": [
    "def load_data(isTest,img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=2100*3   # 데이터는 2100개씩 있음\n",
    "    if(isTest):\n",
    "        number_of_data= 100 * 3\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    suffix = 'all'\n",
    "    if(isTest):\n",
    "        suffix = 'test'\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/scissor_{}/*.jpg'.format(suffix)):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_{}/*.jpg'.format(suffix)):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_{}/*.jpg'.format(suffix)):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"{} 이미지 개수는\".format(suffix),idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rcp_all/\"\n",
    "(x_train, y_train)=load_data(False,image_dir_path)\n",
    "\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "(x_test, y_test)=load_data(True,image_dir_path)\n",
    "\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "\n",
    "## train,test 구분하여 사용할 때 사용하였음\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_whole,y_whole, test_size=0.1, shuffle=True, random_state=500)\n",
    "# print(\"x_train shape: {}\".format(x_train.shape))\n",
    "# print(\"x_test shape: {}\".format(x_test.shape))\n",
    "# print(\"y_train shape: {}\".format(y_train.shape))\n",
    "# print(\"y_test shape: {}\".format(y_test.shape))\n",
    "# x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "# x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "라벨:  2\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p526a0a1b83)\">\n    <image height=\"218\" id=\"image5ff063b3af\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mc459fe40b9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#mc459fe40b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#mc459fe40b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#mc459fe40b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#mc459fe40b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#mc459fe40b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#mc459fe40b9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"ma2de746902\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2de746902\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2de746902\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2de746902\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2de746902\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2de746902\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2de746902\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p526a0a1b83\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(x_train[601])\n",
    "# print('라벨: ', y_train[601])\n",
    "plt.imshow(x_test[201])\n",
    "print('라벨: ', y_test[201])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model에 추가된 Layer 개수:  7\nModel: \"sequential_21\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_42 (Conv2D)           (None, 26, 26, 32)        896       \n_________________________________________________________________\nmax_pooling2d_42 (MaxPooling (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_43 (Conv2D)           (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_43 (MaxPooling (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten_21 (Flatten)         (None, 1600)              0         \n_________________________________________________________________\ndense_42 (Dense)             (None, 64)                102464    \n_________________________________________________________________\ndense_43 (Dense)             (None, 3)                 195       \n=================================================================\nTotal params: 122,051\nTrainable params: 122,051\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "n_image_channel = 3\n",
    "n_classes = 3\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,n_image_channel)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.6841\nEpoch 2/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8737\nEpoch 3/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9368\nEpoch 4/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9648\nEpoch 5/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9795\nEpoch 6/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9851\nEpoch 7/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9930\nEpoch 8/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9951\nEpoch 9/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9960\nEpoch 10/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9981\nEpoch 11/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 0.9997\nEpoch 12/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000\nEpoch 13/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\nEpoch 14/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\nEpoch 15/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 16/20\n197/197 [==============================] - 0s 1ms/step - loss: 8.7861e-04 - accuracy: 1.0000\nEpoch 17/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9856\nEpoch 18/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.9994\nEpoch 19/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.9995\nEpoch 20/20\n197/197 [==============================] - 0s 1ms/step - loss: 7.3613e-04 - accuracy: 1.0000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f399c0241d0>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트\n",
    "테스트 데이터는 이미 만들어져 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "x_test shape: (300, 28, 28, 3)\ny_test shape: (300,)\n"
    }
   ],
   "source": [
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss, accuracy 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10/10 - 0s - loss: 1.4979 - accuracy: 0.7333\ntest_loss: 1.4978870153427124 \ntest_accuracy: 0.7333333492279053\nmodel.predict() 결과 :  [1.4432995e-03 9.9792081e-01 6.3597754e-04]\nmodel이 추론한 가장 가능성이 높은 결과 :  1\n실제 데이터의 라벨 :  0\n"
    }
   ],
   "source": [
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "\n",
    "predicted_result = model.predict(x_test_norm)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=3  #4번째 x_test를 살펴보자. \n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 더 좋은 네트워크 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model에 추가된 Layer 개수:  8\nModel: \"sequential_23\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_46 (Conv2D)           (None, 26, 26, 64)        1792      \n_________________________________________________________________\nmax_pooling2d_46 (MaxPooling (None, 13, 13, 64)        0         \n_________________________________________________________________\nconv2d_47 (Conv2D)           (None, 11, 11, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_47 (MaxPooling (None, 5, 5, 128)         0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 5, 5, 128)         0         \n_________________________________________________________________\nflatten_23 (Flatten)         (None, 3200)              0         \n_________________________________________________________________\ndense_46 (Dense)             (None, 128)               409728    \n_________________________________________________________________\ndense_47 (Dense)             (None, 3)                 387       \n=================================================================\nTotal params: 485,763\nTrainable params: 485,763\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.6708\nEpoch 2/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8784\nEpoch 3/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9244\nEpoch 4/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9537\nEpoch 5/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9676\nEpoch 6/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9725\nEpoch 7/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9773\nEpoch 8/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9835\nEpoch 9/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9835\nEpoch 10/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9873\nEpoch 11/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9887\nEpoch 12/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9913\nEpoch 13/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9922\nEpoch 14/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9879\nEpoch 15/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9913\nEpoch 16/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9916\nEpoch 17/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9957\nEpoch 18/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9957\nEpoch 19/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9933\nEpoch 20/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9937\n10/10 - 0s - loss: 1.3295 - accuracy: 0.7567\n===================== result ================== \nn_channel_1: 64\nn_channel_2: 128\nn_dense: 128\nn_train_epoch: 20\ntest_loss: 1.3294609785079956 \ntest_accuracy: 0.7566666603088379\n"
    }
   ],
   "source": [
    "n_channel_1= 64\n",
    "n_channel_2= 128\n",
    "n_dense= 128\n",
    "n_train_epoch= 20\n",
    "\n",
    "n_image_channel = 3\n",
    "n_classes = 3\n",
    "# 모델 설계\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,n_image_channel)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 테스트\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"===================== result ================== \")\n",
    "print(\"n_channel_1: {}\".format(n_channel_1))\n",
    "print(\"n_channel_2: {}\".format(n_channel_2))\n",
    "print(\"n_dense: {}\".format(n_dense))\n",
    "print(\"n_train_epoch: {}\".format(n_train_epoch))\n",
    "\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "\n",
    "\n",
    "# predicted_result = model.predict(x_test_norm)  # model이 추론한 확률값. \n",
    "# predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "# idx=3  #4번째 x_test를 살펴보자. \n",
    "# print('model.predict() 결과 : ', predicted_result[idx])\n",
    "# print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "# print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가장 높은 정확도 결과\n",
    "\n",
    "n_channel_1: 64    \n",
    "n_channel_2: 128     \n",
    "n_dense: 128    \n",
    "n_train_epoch: 20    \n",
    "test_loss: 1.3294609785079956     \n",
    "test_accuracy: 0.7566666603088379"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}