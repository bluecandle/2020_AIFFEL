{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: pillow in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (7.0.0)\n"
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "# 필요한 라이브러리 가져오기\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 크기 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/scissor_all\nscissor_all 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/rock_all\nrock_all 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/paper_all\npaper_all 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/scissor_test\nscissor_test 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/rock_test\nrock_test 이미지 resize 완료!\n이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rcp_all/paper_test\npaper_test 이미지 resize 완료!\n"
    }
   ],
   "source": [
    "\n",
    "def convertImageSize(name):\n",
    "    image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rcp_all/\"+name\n",
    "    print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "    images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "    img_size = 28\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(img_size,img_size)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img,\"JPEG\")\n",
    "\n",
    "    print(\"{} 이미지 resize 완료!\".format(name))\n",
    "\n",
    "dirs = ['scissor_all','rock_all','paper_all','scissor_test','rock_test','paper_test']\n",
    "for c in dirs:\n",
    "    convertImageSize(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전부 불러오고, ~~train/test 데이터 분리~~\n",
    "[데이터 분리 참조](https://rfriend.tistory.com/519)\n",
    "\n",
    "원래 5조의 전체 데이터 (2100장씩 6300장) 를 임의로 train, test 데이터로 구분하여 사용하였음.    \n",
    "근데, 그렇게 하면 정확도가 약 99% 정도가 나오는 비정상적인 상황이 발생.    \n",
    "따라서, 다른 인원의 데이터를 test dataset 으로 사용할 필요를 느껴서, 변경하였음. (이영빈님 데이터 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "all 이미지 개수는 6300 입니다.\nx_train shape: (6300, 28, 28, 3)\ny_train shape: (6300,)\ntest 이미지 개수는 300 입니다.\nx_test shape: (300, 28, 28, 3)\ny_test shape: (300,)\n"
    }
   ],
   "source": [
    "def load_data(isTest,img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=2100*3   # 데이터는 2100개씩 있음\n",
    "    if(isTest):\n",
    "        number_of_data= 100 * 3\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    suffix = 'all'\n",
    "    if(isTest):\n",
    "        suffix = 'test'\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/scissor_{}/*.jpg'.format(suffix)):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_{}/*.jpg'.format(suffix)):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_{}/*.jpg'.format(suffix)):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"{} 이미지 개수는\".format(suffix),idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rcp_all/\"\n",
    "(x_train, y_train)=load_data(False,image_dir_path)\n",
    "\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "(x_test, y_test)=load_data(True,image_dir_path)\n",
    "\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "\n",
    "## train,test 구분하여 사용할 때 사용하였음\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_whole,y_whole, test_size=0.1, shuffle=True, random_state=500)\n",
    "# print(\"x_train shape: {}\".format(x_train.shape))\n",
    "# print(\"x_test shape: {}\".format(x_test.shape))\n",
    "# print(\"y_train shape: {}\".format(y_train.shape))\n",
    "# print(\"y_test shape: {}\".format(y_test.shape))\n",
    "# x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "# x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "라벨:  2\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pbb785a7f5a)\">\n    <image height=\"218\" id=\"image121ea12806\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m08d6c7eb4e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m08d6c7eb4e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m08d6c7eb4e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m08d6c7eb4e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m08d6c7eb4e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m08d6c7eb4e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m08d6c7eb4e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"ma0931cd4cc\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma0931cd4cc\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma0931cd4cc\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma0931cd4cc\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma0931cd4cc\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma0931cd4cc\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma0931cd4cc\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pbb785a7f5a\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(x_train[601])\n",
    "# print('라벨: ', y_train[601])\n",
    "plt.imshow(x_test[201])\n",
    "print('라벨: ', y_test[201])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model에 추가된 Layer 개수:  7\nModel: \"sequential_24\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_48 (Conv2D)           (None, 26, 26, 32)        896       \n_________________________________________________________________\nmax_pooling2d_48 (MaxPooling (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_49 (Conv2D)           (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_49 (MaxPooling (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten_24 (Flatten)         (None, 1600)              0         \n_________________________________________________________________\ndense_48 (Dense)             (None, 64)                102464    \n_________________________________________________________________\ndense_49 (Dense)             (None, 3)                 195       \n=================================================================\nTotal params: 122,051\nTrainable params: 122,051\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "n_image_channel = 3\n",
    "n_classes = 3\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,n_image_channel)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.7600 - accuracy: 0.6586\nEpoch 2/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8760\nEpoch 3/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.9341\nEpoch 4/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9694\nEpoch 5/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9840\nEpoch 6/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9871\nEpoch 7/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9916\nEpoch 8/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9962\nEpoch 9/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.9975\nEpoch 10/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 0.9984\nEpoch 11/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9971\nEpoch 12/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 0.9981\nEpoch 13/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 0.9990\nEpoch 14/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9997\nEpoch 15/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.9994\nEpoch 16/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.9900\nEpoch 17/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9938\nEpoch 18/20\n197/197 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9997\nEpoch 19/20\n197/197 [==============================] - 0s 1ms/step - loss: 9.0833e-04 - accuracy: 1.0000\nEpoch 20/20\n197/197 [==============================] - 0s 1ms/step - loss: 4.8791e-04 - accuracy: 1.0000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f38e822b450>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트\n",
    "테스트 데이터는 이미 만들어져 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "x_test shape: (300, 28, 28, 3)\ny_test shape: (300,)\n"
    }
   ],
   "source": [
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss, accuracy 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10/10 - 0s - loss: 1.4166 - accuracy: 0.7633\ntest_loss: 1.4165854454040527 \ntest_accuracy: 0.7633333206176758\nmodel.predict() 결과 :  [2.5858601e-05 9.8492265e-01 1.5051498e-02]\nmodel이 추론한 가장 가능성이 높은 결과 :  1\n실제 데이터의 라벨 :  0\n"
    }
   ],
   "source": [
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "\n",
    "predicted_result = model.predict(x_test_norm)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=3  #4번째 x_test를 살펴보자. \n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 더 좋은 네트워크 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model에 추가된 Layer 개수:  8\nModel: \"sequential_25\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_50 (Conv2D)           (None, 26, 26, 64)        1792      \n_________________________________________________________________\nmax_pooling2d_50 (MaxPooling (None, 13, 13, 64)        0         \n_________________________________________________________________\nconv2d_51 (Conv2D)           (None, 11, 11, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_51 (MaxPooling (None, 5, 5, 128)         0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 5, 5, 128)         0         \n_________________________________________________________________\nflatten_25 (Flatten)         (None, 3200)              0         \n_________________________________________________________________\ndense_50 (Dense)             (None, 128)               409728    \n_________________________________________________________________\ndense_51 (Dense)             (None, 3)                 387       \n=================================================================\nTotal params: 485,763\nTrainable params: 485,763\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.7698 - accuracy: 0.6324\nEpoch 2/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8478\nEpoch 3/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9113\nEpoch 4/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9425\nEpoch 5/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9624\nEpoch 6/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9759\nEpoch 7/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9789\nEpoch 8/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9838\nEpoch 9/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9883\nEpoch 10/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9879\nEpoch 11/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9900\nEpoch 12/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9951\nEpoch 13/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9887\nEpoch 14/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9919\nEpoch 15/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9935\nEpoch 16/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9925\nEpoch 17/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9932\nEpoch 18/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9906\nEpoch 19/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9937\nEpoch 20/20\n197/197 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9956\n10/10 - 0s - loss: 0.8455 - accuracy: 0.7667\n===================== result ================== \nn_channel_1: 64\nn_channel_2: 128\nn_dense: 128\nn_train_epoch: 20\ntest_loss: 0.8454890847206116 \ntest_accuracy: 0.7666666507720947\n"
    }
   ],
   "source": [
    "n_channel_1= 64\n",
    "n_channel_2= 128\n",
    "n_dense= 128\n",
    "n_train_epoch= 20\n",
    "\n",
    "n_image_channel = 3\n",
    "n_classes = 3\n",
    "# 모델 설계\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,n_image_channel)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 테스트\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"===================== result ================== \")\n",
    "print(\"n_channel_1: {}\".format(n_channel_1))\n",
    "print(\"n_channel_2: {}\".format(n_channel_2))\n",
    "print(\"n_dense: {}\".format(n_dense))\n",
    "print(\"n_train_epoch: {}\".format(n_train_epoch))\n",
    "\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "\n",
    "\n",
    "# predicted_result = model.predict(x_test_norm)  # model이 추론한 확률값. \n",
    "# predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "# idx=3  #4번째 x_test를 살펴보자. \n",
    "# print('model.predict() 결과 : ', predicted_result[idx])\n",
    "# print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "# print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가장 높은 정확도 결과\n",
    "\n",
    "n_channel_1: 64\n",
    "n_channel_2: 128\n",
    "n_dense: 128\n",
    "n_train_epoch: 20\n",
    "test_loss: 0.8454890847206116 \n",
    "test_accuracy: 0.7666666507720947"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과 보고서\n",
    "========\n",
    "\n",
    "## 데이터 수집\n",
    "원래 직접 찍은 사진 900장 (각 300장)을 훈련 데이터셋으로 사용하고, 다른 조원의 데이터 2100장(각 700장)을 테스트 데이터셋으로 사용하였다.\n",
    "그런데, 파이퍼파라미터를 여러 방향으로 수정해보아도 결과 값이 대략 45~55% 정도로 나타났어서, 성능을 향상시킬 방법을 해각하게 되었다.\n",
    "훈련 데이터를 더 많이 투입시키는 방법이 좋겠다고 생각하여, 조원들의 데이터를 다 모았다. (2100장씩 6300장)\n",
    "그리고, 해당 데이터를 임의로 8:2, 9:1 비율로 나누어 훈련 데이터셋과 테스트 데이터셋으로 사용하였다.\n",
    "\n",
    "## 비슷한 특징을 가진 이미지의 문제점\n",
    "조원들의 전체 데이터를 하나의 풀로 두고 그 안에서 훈련, 테스트 데이터를 나누고 학습을 진행하니, 약 99%에 가까운 결과들이 지속적으로 나타났다.\n",
    "그래서, 비슷한 환경에서 찍은 사진들, 즉 비슷한 특징을 가진 이미지들을 임의로 나누어 훈련 및 테스트를 진행하는 것이 유의미한 작업은 아니라고 생각되었다.\n",
    "\n",
    "## 다른 사람의 데이터를 테스트 데이터로 사용하자.\n",
    "그래서, 슬랙에 올라와 있는 다른 분의 데이터셋을 테스트 데이터로 사용하고, 조 전체 데이터는 훈련 데이터로 사용하였다.\n",
    "그랬더니, 역시나 이전의 결과보다는 조금 더 낮은 정확도가 출력되었다.\n",
    "\n",
    "### 의문점\n",
    "하이퍼파라미터가 모두 동일하여도, 모델을 학습시킬 때마다 훈련의 결과가 다르게 나타나는 것으로 보였다.\n",
    "슬랙 내에서 해당 내용에 대한 논의가 이루어지고 있기도 한 것으로 보였는데, 추후 설명이 있었으면 좋겠다고 생각한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}