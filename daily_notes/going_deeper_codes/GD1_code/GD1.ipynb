{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('aiffel': conda)",
   "display_name": "Python 3.7.7 64-bit ('aiffel': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f5a23dafa1167ad26407da34d61d47c6735277f7e3900a1acafb810bbe457929"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 프로젝트: ResNet Ablation Study"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from keras import models, layers\n",
    "# from keras import Input\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras import optimizers, initializers, regularizers, metrics\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#tfds.disable_progress_bar()   # 이 주석을 풀면 데이터셋 다운로드과정의 프로그레스바가 나타나지 않습니다.\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops._OptionsDataset"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "type(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FeaturesDict({\n    'id': Text(shape=(), dtype=tf.string),\n    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n})\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow 데이터셋을 로드하면 꼭 feature 정보를 확인해 보세요. \n",
    "print(ds_info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(50000, shape=(), dtype=int64)\ntf.Tensor(10000, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 개수도 확인해 봅시다. \n",
    "print(tf.data.experimental.cardinality(ds_train))\n",
    "print(tf.data.experimental.cardinality(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    # image = tf.image.resize(image, [32, 32])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=1\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "source": [
    "## ResNet 기본 블록 구성하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building VGG Block\n",
    "\n",
    "# block_num : 블록 이름 붙이기 위해\n",
    "# is_50 ResNet-50인지 구분하기 위해\n",
    "def build_resnet_block(input_layer,\n",
    "                    num_cnn=3, \n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                    is_50 = False\n",
    "                   ):    \n",
    "\n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "    # shortcut 생성\n",
    "    x_shortcut = x\n",
    "\n",
    "    # ResNet-50인 경우\n",
    "    if is_50:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            print('========== ResNet-50 Block_{}_{} =============='.format(block_num,cnn_num))\n",
    "            \n",
    "            # 첫 번째 블록을 제외한 나머지 블록에서 첫 번째 conv layer 는 stride 가 (2,2) 이어야 한다.\n",
    "            # 그리고 첫 번째 블록들은 다 마지막에 shortcut 모양맞춰주기를 해야한다.\n",
    "\n",
    "            strides = (1,1)                  \n",
    "            # 첫 번째 블록의 첫 번째 conv layer만 stides (1,1)이고 나머지 블록의 첫 번째 conv layer 는 (2,2)임.\n",
    "            if cnn_num == 0 and block_num != 0:\n",
    "                strides = (2,2)                                \n",
    "                              \n",
    "            x = Conv2D(filters = channel, kernel_size = (1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), strides= strides, padding='valid', name=f'block_{block_num}_1x1_{cnn_num}_1')(x)\n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_1')(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filters = channel, kernel_size = (3,3), kernel_regularizer=keras.regularizers.l2(0.0001), strides= (1,1), padding='same',  name=f'block_{block_num}_conv_{cnn_num}')(x)\n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_2')(x)\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            x = Conv2D(filters = channel*4, kernel_size = (1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), strides= (1,1), padding='valid', name=f'block_{block_num}_1x1_{cnn_num}_2')(x)                \n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_3')(x)\n",
    "            \n",
    "            # 각 블록의 첫 번째 conv layer 인 경우, shortcut 모양 맞춰주기\n",
    "            if cnn_num == 0:\n",
    "\n",
    "                x_shortcut = Conv2D(filters = channel*4, kernel_size = (1, 1), kernel_regularizer=keras.regularizers.l2(0.0001),strides=strides, padding='valid')(x_shortcut)        \n",
    "                x_shortcut = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_shortcut')(x_shortcut)\n",
    "    \n",
    "            x = Add()([x, x_shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "                \n",
    "            x_shortcut = x\n",
    "                \n",
    "    #  ResNet-34인 경우\n",
    "    else:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            print('========== ResNet-34 Block_{}_{} =============='.format(block_num,cnn_num))\n",
    "\n",
    "            strides = (1,1)                  \n",
    "            # 첫 번째 블록의 첫 번째 conv layer만 stides (1,1)이고 나머지 블록의 첫 번째 conv layer 는(2,2)임.\n",
    "            if cnn_num == 0 and block_num != 0:\n",
    "                strides = (2,2)  \n",
    "                     \n",
    "            x = Conv2D(filters = channel, kernel_size = (3, 3), kernel_regularizer=keras.regularizers.l2(0.0001), strides= strides, padding='same', name=f'block_{block_num}_conv_{cnn_num}_1')(x)\n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_1')(x)\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            x = Conv2D(filters = channel, kernel_size = (3,3), kernel_regularizer=keras.regularizers.l2(0.0001), strides= (1,1), padding='same',  name=f'block_{block_num}_conv_{cnn_num}_2')(x)\n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_2')(x)\n",
    "\n",
    "            # 각 블록의 첫 번째 conv layer 인 경우, shortcut 모양 맞춰주기\n",
    "            if cnn_num == 0:\n",
    "\n",
    "                x_shortcut = Conv2D(filters = channel, kernel_size = (1, 1), kernel_regularizer=keras.regularizers.l2(0.0001),strides=strides, padding='valid')(x_shortcut)            \n",
    "                x_shortcut = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_shortcut')(x_shortcut)                              \n",
    "            x = keras.layers.Add()([x,x_shortcut])\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x_shortcut = x\n",
    "\n",
    "    return x"
   ]
  },
  {
   "source": [
    "## ResNet-34, ResNet-50 Complete Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape=(32,32,3),is_50 = False, num_classes=1000):\n",
    "\n",
    "    num_cnn_list = [3,4,6,3]\n",
    "    channel_list = [64,128,256,512]\n",
    "    num_classes = num_classes\n",
    "\n",
    "    input_layer = Input(shape=input_shape, dtype='float32', name='input')  # input layer를 만들어둡니다.\n",
    "    \n",
    "    x = input_layer\n",
    "    \n",
    "    # conv_1 layer    \n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    # (32+6 , 32+6, 3)\n",
    "    # print(x)    \n",
    "\n",
    "    x = Conv2D(\n",
    "            filters=64,                        \n",
    "            kernel_size=(7,7),\n",
    "            kernel_regularizer=keras.regularizers.l2(0.0001),\n",
    "            strides = (2,2),\n",
    "            name ='conv1'\n",
    "        )(x)\n",
    "\n",
    "    # 기본 옵션이 valid로 되어있는데, valid 의 식 자체가 아래 두 줄 과 같은 모양임.\n",
    "    # out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "    # out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "\n",
    "    # 위에 따르면,\n",
    "    # (38 - 7 + 2*0)/2 + 1 = 31/2 = 15.5, 15.5 + 1 = 16.5 ?? 이런 모양이 아니라\n",
    "    # ceil((38 - 7 + 1)/2) 임. => ceil(32/2) = 16 이런 모양임.    \n",
    "    # 따라서, (16,16,64)    \n",
    "    # print(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)    \n",
    "    \n",
    "    # (16+2,16+2,64)\n",
    "    # print(x)\n",
    "\n",
    "    # conv_2 layer maxpool 먼저\n",
    "    x = MaxPooling2D(\n",
    "            pool_size=(3, 3),\n",
    "            strides=2,\n",
    "            name=f'conv2_max_pool'\n",
    "        )(x)\n",
    "\n",
    "    # (18 - 3 + 2*0)/2 +1 = 15/2 + 1 = 7.5 +1 = 8.5 ??        \n",
    "    # (8,8,64)\n",
    "    # print(x)    \n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        x = build_resnet_block(\n",
    "            input_layer = x,\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,  \n",
    "            block_num=i,\n",
    "            is_50 = is_50\n",
    "        )\n",
    "\n",
    "    x = GlobalAveragePooling2D(name=f'average_pool')(x)    \n",
    "    output = keras.layers.Dense(num_classes, kernel_regularizer=keras.regularizers.l2(0.0001), activation='softmax', name='fc')(x)   \n",
    "\n",
    "    model = keras.Model(\n",
    "        inputs = input_layer,\n",
    "        outputs = output\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_1_0_bn_shortcut (BatchNor (None, 4, 4, 128)    512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 128)    0           block_1_0_bn_2[0][0]             \n",
      "                                                                 block_1_0_bn_shortcut[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4, 4, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_1_1 (Conv2D)       (None, 4, 4, 128)    147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_1_bn_1 (BatchNormalizat (None, 4, 4, 128)    512         block_1_conv_1_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 4, 4, 128)    0           block_1_1_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_1_2 (Conv2D)       (None, 4, 4, 128)    147584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_1_bn_2 (BatchNormalizat (None, 4, 4, 128)    512         block_1_conv_1_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 128)    0           block_1_1_bn_2[0][0]             \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 128)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_2_1 (Conv2D)       (None, 4, 4, 128)    147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1_2_bn_1 (BatchNormalizat (None, 4, 4, 128)    512         block_1_conv_2_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 128)    0           block_1_2_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_2_2 (Conv2D)       (None, 4, 4, 128)    147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1_2_bn_2 (BatchNormalizat (None, 4, 4, 128)    512         block_1_conv_2_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 128)    0           block_1_2_bn_2[0][0]             \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 128)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_3_1 (Conv2D)       (None, 4, 4, 128)    147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1_3_bn_1 (BatchNormalizat (None, 4, 4, 128)    512         block_1_conv_3_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 128)    0           block_1_3_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_3_2 (Conv2D)       (None, 4, 4, 128)    147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1_3_bn_2 (BatchNormalizat (None, 4, 4, 128)    512         block_1_conv_3_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 128)    0           block_1_3_bn_2[0][0]             \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 128)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_0_1 (Conv2D)       (None, 2, 2, 256)    295168      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_0_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_0_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2, 2, 256)    0           block_2_0_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_0_2 (Conv2D)       (None, 2, 2, 256)    590080      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 2, 2, 256)    33024       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_0_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_0_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_2_0_bn_shortcut (BatchNor (None, 2, 2, 256)    1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 256)    0           block_2_0_bn_2[0][0]             \n",
      "                                                                 block_2_0_bn_shortcut[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 2, 2, 256)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_1_1 (Conv2D)       (None, 2, 2, 256)    590080      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_1_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 2, 2, 256)    0           block_2_1_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_1_2 (Conv2D)       (None, 2, 2, 256)    590080      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_1_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 256)    0           block_2_1_bn_2[0][0]             \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 2, 2, 256)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_2_1 (Conv2D)       (None, 2, 2, 256)    590080      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_2_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_2_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 2, 2, 256)    0           block_2_2_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_2_2 (Conv2D)       (None, 2, 2, 256)    590080      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_2_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_2_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 256)    0           block_2_2_bn_2[0][0]             \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 2, 2, 256)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_3_1 (Conv2D)       (None, 2, 2, 256)    590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_3_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_3_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 2, 2, 256)    0           block_2_3_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_3_2 (Conv2D)       (None, 2, 2, 256)    590080      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_3_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_3_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 256)    0           block_2_3_bn_2[0][0]             \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 2, 2, 256)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_4_1 (Conv2D)       (None, 2, 2, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_4_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_4_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 2, 2, 256)    0           block_2_4_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_4_2 (Conv2D)       (None, 2, 2, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_4_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_4_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 2, 256)    0           block_2_4_bn_2[0][0]             \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 256)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_5_1 (Conv2D)       (None, 2, 2, 256)    590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_5_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_5_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 2, 2, 256)    0           block_2_5_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_5_2 (Conv2D)       (None, 2, 2, 256)    590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_5_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_5_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 2, 2, 256)    0           block_2_5_bn_2[0][0]             \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2, 2, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_0_1 (Conv2D)       (None, 1, 1, 512)    1180160     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_0_bn_1 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_conv_0_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1, 1, 512)    0           block_3_0_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_0_2 (Conv2D)       (None, 1, 1, 512)    2359808     activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1, 1, 512)    131584      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_0_bn_2 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_conv_0_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_3_0_bn_shortcut (BatchNor (None, 1, 1, 512)    2048        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1, 1, 512)    0           block_3_0_bn_2[0][0]             \n",
      "                                                                 block_3_0_bn_shortcut[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1, 1, 512)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_1_1 (Conv2D)       (None, 1, 1, 512)    2359808     activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1_bn_1 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_conv_1_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 1, 1, 512)    0           block_3_1_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_1_2 (Conv2D)       (None, 1, 1, 512)    2359808     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1_bn_2 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_conv_1_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1, 1, 512)    0           block_3_1_bn_2[0][0]             \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1, 1, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_2_1 (Conv2D)       (None, 1, 1, 512)    2359808     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_2_bn_1 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_conv_2_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1, 1, 512)    0           block_3_2_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_2_2 (Conv2D)       (None, 1, 1, 512)    2359808     activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_2_bn_2 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_conv_2_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 1, 512)    0           block_3_2_bn_2[0][0]             \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1, 1, 512)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pool (GlobalAveragePool (None, 512)          0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 10)           5130        average_pool[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 21,319,754\n",
      "Trainable params: 21,302,602\n",
      "Non-trainable params: 17,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# cifar-10 을 대상으로 하는 모델\n",
    "resnet_34_cifar10 = build_resnet(input_shape=(32,32,3),is_50 = False, num_classes=10)\n",
    "resnet_34_cifar10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_0_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_1x1_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 2, 2, 256)    0           block_2_0_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_0 (Conv2D)         (None, 2, 2, 256)    590080      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_0_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 2, 2, 256)    0           block_2_0_bn_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_0_2 (Conv2D)        (None, 2, 2, 1024)   263168      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 2, 2, 1024)   525312      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_0_bn_3 (BatchNormalizat (None, 2, 2, 1024)   4096        block_2_1x1_0_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_0_bn_shortcut (BatchNor (None, 2, 2, 1024)   4096        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 2, 2, 1024)   0           block_2_0_bn_3[0][0]             \n",
      "                                                                 block_2_0_bn_shortcut[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 2, 2, 1024)   0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_1_1 (Conv2D)        (None, 2, 2, 256)    262400      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_1x1_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 2, 2, 256)    0           block_2_1_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_1 (Conv2D)         (None, 2, 2, 256)    590080      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 2, 2, 256)    0           block_2_1_bn_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_1_2 (Conv2D)        (None, 2, 2, 1024)   263168      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1_bn_3 (BatchNormalizat (None, 2, 2, 1024)   4096        block_2_1x1_1_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 2, 2, 1024)   0           block_2_1_bn_3[0][0]             \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 2, 2, 1024)   0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_2_1 (Conv2D)        (None, 2, 2, 256)    262400      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_2_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_1x1_2_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 2, 2, 256)    0           block_2_2_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_2 (Conv2D)         (None, 2, 2, 256)    590080      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_2_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 2, 2, 256)    0           block_2_2_bn_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_2_2 (Conv2D)        (None, 2, 2, 1024)   263168      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_2_bn_3 (BatchNormalizat (None, 2, 2, 1024)   4096        block_2_1x1_2_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 2, 2, 1024)   0           block_2_2_bn_3[0][0]             \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 2, 2, 1024)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_3_1 (Conv2D)        (None, 2, 2, 256)    262400      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_3_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_1x1_3_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 2, 2, 256)    0           block_2_3_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_3 (Conv2D)         (None, 2, 2, 256)    590080      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_3_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 2, 2, 256)    0           block_2_3_bn_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_3_2 (Conv2D)        (None, 2, 2, 1024)   263168      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_3_bn_3 (BatchNormalizat (None, 2, 2, 1024)   4096        block_2_1x1_3_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 2, 2, 1024)   0           block_2_3_bn_3[0][0]             \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 2, 2, 1024)   0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_4_1 (Conv2D)        (None, 2, 2, 256)    262400      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_4_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_1x1_4_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 2, 2, 256)    0           block_2_4_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_4 (Conv2D)         (None, 2, 2, 256)    590080      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_4_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 2, 2, 256)    0           block_2_4_bn_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_4_2 (Conv2D)        (None, 2, 2, 1024)   263168      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_4_bn_3 (BatchNormalizat (None, 2, 2, 1024)   4096        block_2_1x1_4_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 2, 2, 1024)   0           block_2_4_bn_3[0][0]             \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 2, 2, 1024)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_5_1 (Conv2D)        (None, 2, 2, 256)    262400      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_5_bn_1 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_1x1_5_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 2, 2, 256)    0           block_2_5_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_5 (Conv2D)         (None, 2, 2, 256)    590080      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_5_bn_2 (BatchNormalizat (None, 2, 2, 256)    1024        block_2_conv_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 256)    0           block_2_5_bn_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_1x1_5_2 (Conv2D)        (None, 2, 2, 1024)   263168      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_5_bn_3 (BatchNormalizat (None, 2, 2, 1024)   4096        block_2_1x1_5_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 2, 2, 1024)   0           block_2_5_bn_3[0][0]             \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 2, 2, 1024)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1x1_0_1 (Conv2D)        (None, 1, 1, 512)    524800      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_0_bn_1 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_1x1_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 1, 1, 512)    0           block_3_0_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_0 (Conv2D)         (None, 1, 1, 512)    2359808     activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_0_bn_2 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 1, 1, 512)    0           block_3_0_bn_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1x1_0_2 (Conv2D)        (None, 1, 1, 2048)   1050624     activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 1, 1, 2048)   2099200     activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_0_bn_3 (BatchNormalizat (None, 1, 1, 2048)   8192        block_3_1x1_0_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3_0_bn_shortcut (BatchNor (None, 1, 1, 2048)   8192        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 1, 1, 2048)   0           block_3_0_bn_3[0][0]             \n",
      "                                                                 block_3_0_bn_shortcut[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 1, 1, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1x1_1_1 (Conv2D)        (None, 1, 1, 512)    1049088     activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1_bn_1 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_1x1_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 1, 1, 512)    0           block_3_1_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_1 (Conv2D)         (None, 1, 1, 512)    2359808     activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1_bn_2 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 1, 1, 512)    0           block_3_1_bn_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1x1_1_2 (Conv2D)        (None, 1, 1, 2048)   1050624     activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1_bn_3 (BatchNormalizat (None, 1, 1, 2048)   8192        block_3_1x1_1_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 1, 1, 2048)   0           block_3_1_bn_3[0][0]             \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 1, 1, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1x1_2_1 (Conv2D)        (None, 1, 1, 512)    1049088     activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_2_bn_1 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_1x1_2_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 1, 1, 512)    0           block_3_2_bn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_2_bn_2 (BatchNormalizat (None, 1, 1, 512)    2048        block_3_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 1, 1, 512)    0           block_3_2_bn_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_1x1_2_2 (Conv2D)        (None, 1, 1, 2048)   1050624     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_2_bn_3 (BatchNormalizat (None, 1, 1, 2048)   8192        block_3_1x1_2_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 1, 1, 2048)   0           block_3_2_bn_3[0][0]             \n",
      "                                                                 activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 1, 1, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pool (GlobalAveragePool (None, 2048)         0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 10)           20490       average_pool[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# cifar-10 을 대상으로 하는 모델\n",
    "resnet_50_cifar10 = build_resnet(input_shape=(32,32,3),is_50 = True, num_classes=10)\n",
    "resnet_50_cifar10.summary()"
   ]
  },
  {
   "source": [
    "## 일반 네트워크(plain network) 만들기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building VGG Block\n",
    "\n",
    "# block_num : 블록 이름 붙이기 위해\n",
    "# is_50 plain-50인지 구분하기 위해\n",
    "def build_plain_block(input_layer,\n",
    "                    num_cnn=3, \n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                    is_50 = False\n",
    "                   ):    \n",
    "\n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "\n",
    "    # plain-50인 경우\n",
    "    if is_50:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            print('========== plain-50 Block_{}_{} =============='.format(block_num,cnn_num))\n",
    "            \n",
    "            # 첫 번째 블록을 제외한 나머지 블록에서 첫 번째 conv layer 는 stride 가 (2,2) 이어야 한다.\n",
    "            # 그리고 첫 번째 블록들은 다 마지막에 shortcut 모양맞춰주기를 해야한다.\n",
    "\n",
    "            strides = (1,1)                  \n",
    "            # 첫 번째 블록의 첫 번째 conv layer만 stides (1,1)이고 나머지 블록의 첫 번째 conv layer 는 (2,2)임.\n",
    "            if cnn_num == 0 and block_num != 0:\n",
    "                strides = (2,2)                                \n",
    "\n",
    "            x = Conv2D(filters = channel, kernel_size = (1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), strides= strides, padding='valid', name=f'block_{block_num}_1x1_{cnn_num}_1')(x)\n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_1')(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filters = channel, kernel_size = (3,3), kernel_regularizer=keras.regularizers.l2(0.0001), strides= (1,1), padding='same',  name=f'block_{block_num}_conv_{cnn_num}')(x)\n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_2')(x)\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            x = Conv2D(filters = channel*4, kernel_size = (1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), strides= (1,1), padding='valid', name=f'block_{block_num}_1x1_{cnn_num}_2')(x)                \n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_3')(x)\n",
    "            x = Activation('relu')(x)                       \n",
    "                \n",
    "    # plain-34인 경우\n",
    "    else:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            print('========== plain-34 Block_{}_{} =============='.format(block_num,cnn_num))\n",
    "\n",
    "            strides = (1,1)                  \n",
    "            # 첫 번째 블록의 첫 번째 conv layer만 stides (1,1)이고 나머지 블록의 첫 번째 conv layer 는(2,2)임.\n",
    "            if cnn_num == 0 and block_num != 0:\n",
    "                strides = (2,2)  \n",
    "                     \n",
    "            x = Conv2D(filters = channel, kernel_size = (3, 3), kernel_regularizer=keras.regularizers.l2(0.0001), strides= strides, padding='same', name=f'block_{block_num}_conv_{cnn_num}_1')(x)\n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_1')(x)\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            x = Conv2D(filters = channel, kernel_size = (3,3), kernel_regularizer=keras.regularizers.l2(0.0001), strides= (1,1), padding='same',  name=f'block_{block_num}_conv_{cnn_num}_2')(x)\n",
    "            x = BatchNormalization(name=f'block_{block_num}_{cnn_num}_bn_2')(x)\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_plain(input_shape=(32,32,3),is_50 = False, num_classes=1000):\n",
    "\n",
    "    num_cnn_list = [3,4,6,3]\n",
    "    channel_list = [64,128,256,512]\n",
    "    num_classes = num_classes\n",
    "\n",
    "    input_layer = Input(shape=input_shape, dtype='float32', name='input')  # input layer를 만들어둡니다.\n",
    "    \n",
    "    x = input_layer\n",
    "    \n",
    "    # conv_1 layer\n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(7,7),\n",
    "            kernel_regularizer=keras.regularizers.l2(0.0001),\n",
    "            strides = (2,2),\n",
    "            name ='conv1'\n",
    "        )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)    \n",
    "\n",
    "    # conv_2 layer maxpool 먼저\n",
    "    x = MaxPooling2D(\n",
    "            pool_size=(3, 3),\n",
    "            strides=2,\n",
    "            name=f'conv2_max_pool'\n",
    "        )(x) \n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        x = build_plain_block(\n",
    "            input_layer = x,\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,            \n",
    "            block_num=i,\n",
    "            is_50 = is_50\n",
    "        )\n",
    "\n",
    "    x = GlobalAveragePooling2D(name=f'average_pool')(x)    \n",
    "    output = keras.layers.Dense(num_classes, kernel_regularizer=keras.regularizers.l2(0.0001), activation='softmax', name='fc')(x)    \n",
    "    model = keras.Model(\n",
    "        inputs = input_layer,\n",
    "        outputs = output\n",
    "    )   \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========== plain-34 Block_0_0 ==============\n",
      "========== plain-34 Block_0_1 ==============\n",
      "========== plain-34 Block_0_2 ==============\n",
      "========== plain-34 Block_1_0 ==============\n",
      "========== plain-34 Block_1_1 ==============\n",
      "========== plain-34 Block_1_2 ==============\n",
      "========== plain-34 Block_1_3 ==============\n",
      "========== plain-34 Block_2_0 ==============\n",
      "========== plain-34 Block_2_1 ==============\n",
      "========== plain-34 Block_2_2 ==============\n",
      "========== plain-34 Block_2_3 ==============\n",
      "========== plain-34 Block_2_4 ==============\n",
      "========== plain-34 Block_2_5 ==============\n",
      "========== plain-34 Block_3_0 ==============\n",
      "========== plain-34 Block_3_1 ==============\n",
      "========== plain-34 Block_3_2 ==============\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 38, 38, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 16, 16, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2_max_pool (MaxPooling2D (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_conv_0_1 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block_0_0_bn_1 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_conv_0_2 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block_0_0_bn_2 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_conv_1_1 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block_0_1_bn_1 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_conv_1_2 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block_0_1_bn_2 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_conv_2_1 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block_0_2_bn_1 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_conv_2_2 (Conv2D)    (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block_0_2_bn_2 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_0_1 (Conv2D)    (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "block_1_0_bn_1 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_0_2 (Conv2D)    (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_0_bn_2 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_1_1 (Conv2D)    (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_1_bn_1 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_1_2 (Conv2D)    (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_1_bn_2 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_2_1 (Conv2D)    (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_2_bn_1 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_2_2 (Conv2D)    (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_2_bn_2 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_3_1 (Conv2D)    (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_3_bn_1 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_3_2 (Conv2D)    (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_3_bn_2 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_0_1 (Conv2D)    (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block_2_0_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_0_2 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_0_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_1_1 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_1_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_1_2 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_1_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_2_1 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_2_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_2_2 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_2_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_3_1 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_3_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_3_2 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_3_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_4_1 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_4_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_4_2 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_4_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_5_1 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_5_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_5_2 (Conv2D)    (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_5_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_3_conv_0_1 (Conv2D)    (None, 1, 1, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block_3_0_bn_1 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_conv_0_2 (Conv2D)    (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block_3_0_bn_2 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_conv_1_1 (Conv2D)    (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block_3_1_bn_1 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_conv_1_2 (Conv2D)    (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block_3_1_bn_2 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_conv_2_1 (Conv2D)    (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block_3_2_bn_1 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_conv_2_2 (Conv2D)    (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block_3_2_bn_2 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "average_pool (GlobalAverageP (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 21,138,826\n",
      "Trainable params: 21,123,594\n",
      "Non-trainable params: 15,232\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# cifar-10 을 위한 모델\n",
    "plain_34_cifar10 = build_plain(input_shape=(32,32,3),is_50 = False, num_classes=10)\n",
    "plain_34_cifar10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "__________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2_max_pool (MaxPooling2D (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_1x1_0_1 (Conv2D)     (None, 8, 8, 64)          4160      \n",
      "_________________________________________________________________\n",
      "block_0_0_bn_1 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_conv_0 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block_0_0_bn_2 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_1x1_0_2 (Conv2D)     (None, 8, 8, 256)         16640     \n",
      "_________________________________________________________________\n",
      "block_0_0_bn_3 (BatchNormali (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_0_1x1_1_1 (Conv2D)     (None, 8, 8, 64)          16448     \n",
      "_________________________________________________________________\n",
      "block_0_1_bn_1 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_conv_1 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block_0_1_bn_2 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_1x1_1_2 (Conv2D)     (None, 8, 8, 256)         16640     \n",
      "_________________________________________________________________\n",
      "block_0_1_bn_3 (BatchNormali (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_0_1x1_2_1 (Conv2D)     (None, 8, 8, 64)          16448     \n",
      "_________________________________________________________________\n",
      "block_0_2_bn_1 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_conv_2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block_0_2_bn_2 (BatchNormali (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block_0_1x1_2_2 (Conv2D)     (None, 8, 8, 256)         16640     \n",
      "_________________________________________________________________\n",
      "block_0_2_bn_3 (BatchNormali (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_1_1x1_0_1 (Conv2D)     (None, 4, 4, 128)         32896     \n",
      "_________________________________________________________________\n",
      "block_1_0_bn_1 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_0 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_0_bn_2 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_1x1_0_2 (Conv2D)     (None, 4, 4, 512)         66048     \n",
      "_________________________________________________________________\n",
      "block_1_0_bn_3 (BatchNormali (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_1_1x1_1_1 (Conv2D)     (None, 4, 4, 128)         65664     \n",
      "_________________________________________________________________\n",
      "block_1_1_bn_1 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_1 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_1_bn_2 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_1x1_1_2 (Conv2D)     (None, 4, 4, 512)         66048     \n",
      "_________________________________________________________________\n",
      "block_1_1_bn_3 (BatchNormali (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_1_1x1_2_1 (Conv2D)     (None, 4, 4, 128)         65664     \n",
      "_________________________________________________________________\n",
      "block_1_2_bn_1 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_2 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_2_bn_2 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_1x1_2_2 (Conv2D)     (None, 4, 4, 512)         66048     \n",
      "_________________________________________________________________\n",
      "block_1_2_bn_3 (BatchNormali (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_1_1x1_3_1 (Conv2D)     (None, 4, 4, 128)         65664     \n",
      "_________________________________________________________________\n",
      "block_1_3_bn_1 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_conv_3 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block_1_3_bn_2 (BatchNormali (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "block_1_1x1_3_2 (Conv2D)     (None, 4, 4, 512)         66048     \n",
      "_________________________________________________________________\n",
      "block_1_3_bn_3 (BatchNormali (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_0_1 (Conv2D)     (None, 2, 2, 256)         131328    \n",
      "_________________________________________________________________\n",
      "block_2_0_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_0 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_0_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_0_2 (Conv2D)     (None, 2, 2, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "block_2_0_bn_3 (BatchNormali (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_1_1 (Conv2D)     (None, 2, 2, 256)         262400    \n",
      "_________________________________________________________________\n",
      "block_2_1_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_1 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_1_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_1_2 (Conv2D)     (None, 2, 2, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "block_2_1_bn_3 (BatchNormali (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_2_1 (Conv2D)     (None, 2, 2, 256)         262400    \n",
      "_________________________________________________________________\n",
      "block_2_2_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_2 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_2_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_2_2 (Conv2D)     (None, 2, 2, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "block_2_2_bn_3 (BatchNormali (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_3_1 (Conv2D)     (None, 2, 2, 256)         262400    \n",
      "_________________________________________________________________\n",
      "block_2_3_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_3 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_3_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_3_2 (Conv2D)     (None, 2, 2, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "block_2_3_bn_3 (BatchNormali (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_4_1 (Conv2D)     (None, 2, 2, 256)         262400    \n",
      "_________________________________________________________________\n",
      "block_2_4_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_4 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_4_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_4_2 (Conv2D)     (None, 2, 2, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "block_2_4_bn_3 (BatchNormali (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_5_1 (Conv2D)     (None, 2, 2, 256)         262400    \n",
      "_________________________________________________________________\n",
      "block_2_5_bn_1 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_conv_5 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block_2_5_bn_2 (BatchNormali (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "block_2_1x1_5_2 (Conv2D)     (None, 2, 2, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "block_2_5_bn_3 (BatchNormali (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block_3_1x1_0_1 (Conv2D)     (None, 1, 1, 512)         524800    \n",
      "_________________________________________________________________\n",
      "block_3_0_bn_1 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_conv_0 (Conv2D)      (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block_3_0_bn_2 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_1x1_0_2 (Conv2D)     (None, 1, 1, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "block_3_0_bn_3 (BatchNormali (None, 1, 1, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "block_3_1x1_1_1 (Conv2D)     (None, 1, 1, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "block_3_1_bn_1 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_conv_1 (Conv2D)      (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block_3_1_bn_2 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_1x1_1_2 (Conv2D)     (None, 1, 1, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "block_3_1_bn_3 (BatchNormali (None, 1, 1, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "block_3_1x1_2_1 (Conv2D)     (None, 1, 1, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "block_3_2_bn_1 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_conv_2 (Conv2D)      (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block_3_2_bn_2 (BatchNormali (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "block_3_1x1_2_2 (Conv2D)     (None, 1, 1, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "block_3_2_bn_3 (BatchNormali (None, 1, 1, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "average_pool (GlobalAverageP (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 20,820,106\n",
      "Trainable params: 20,774,666\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plain_50_cifar10 = build_plain(input_shape=(32,32,3),is_50 = True, num_classes=10)\n",
    "plain_50_cifar10.summary()"
   ]
  },
  {
   "source": [
    "## ResNet-34 vs Plain-34, ResNet-50 vs Plain-50  _ cifar10 _ input_shape : (32,32,3)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We use SGD with a mini-batch size of 256. The learning rate starts from 0.1 and is divided by 10 when the error plateaus, and the models are trained for up to 60×10^4 iterations.\n",
    "We use a weight decay of 0.0001 and a momentum of 0.9\n",
    "\n",
    "60×10^4 iterations 부분은 자원이 한정되어있어 하지 못했다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")\n",
    "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)\n",
    "ds_test = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(factor=0.1)"
   ]
  },
  {
   "source": [
    "### 우선 34 (cifar-10)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "195/195 [==============================] - 53s 272ms/step - loss: 5.8741 - accuracy: 0.1703 - val_loss: 12.3536 - val_accuracy: 0.1219 - lr: 0.1000\n",
      "Epoch 2/20\n",
      "195/195 [==============================] - 14s 72ms/step - loss: 4.8502 - accuracy: 0.2652 - val_loss: 5.1184 - val_accuracy: 0.1456 - lr: 0.1000\n",
      "Epoch 3/20\n",
      "195/195 [==============================] - 14s 71ms/step - loss: 4.3505 - accuracy: 0.3626 - val_loss: 4.5545 - val_accuracy: 0.2542 - lr: 0.1000\n",
      "Epoch 4/20\n",
      "195/195 [==============================] - 14s 72ms/step - loss: 4.0019 - accuracy: 0.4218 - val_loss: 3.9948 - val_accuracy: 0.4049 - lr: 0.1000\n",
      "Epoch 5/20\n",
      "195/195 [==============================] - 14s 72ms/step - loss: 3.7156 - accuracy: 0.4666 - val_loss: 3.7592 - val_accuracy: 0.4219 - lr: 0.1000\n",
      "Epoch 6/20\n",
      "195/195 [==============================] - 14s 71ms/step - loss: 3.4687 - accuracy: 0.5011 - val_loss: 3.5304 - val_accuracy: 0.4653 - lr: 0.1000\n",
      "Epoch 7/20\n",
      "195/195 [==============================] - 14s 71ms/step - loss: 3.2265 - accuracy: 0.5378 - val_loss: 3.4333 - val_accuracy: 0.4676 - lr: 0.1000\n",
      "Epoch 8/20\n",
      "195/195 [==============================] - 14s 71ms/step - loss: 3.0118 - accuracy: 0.5651 - val_loss: 3.0684 - val_accuracy: 0.5304 - lr: 0.1000\n",
      "Epoch 9/20\n",
      "195/195 [==============================] - 14s 71ms/step - loss: 2.8044 - accuracy: 0.6018 - val_loss: 2.9920 - val_accuracy: 0.5250 - lr: 0.1000\n",
      "Epoch 10/20\n",
      "195/195 [==============================] - 14s 71ms/step - loss: 2.6081 - accuracy: 0.6279 - val_loss: 3.2739 - val_accuracy: 0.4234 - lr: 0.1000\n",
      "Epoch 11/20\n",
      "195/195 [==============================] - 14s 73ms/step - loss: 2.4313 - accuracy: 0.6553 - val_loss: 2.6721 - val_accuracy: 0.5532 - lr: 0.1000\n",
      "Epoch 12/20\n",
      "195/195 [==============================] - 14s 72ms/step - loss: 2.2649 - accuracy: 0.6782 - val_loss: 2.7668 - val_accuracy: 0.5147 - lr: 0.1000\n",
      "Epoch 13/20\n",
      "195/195 [==============================] - 14s 72ms/step - loss: 2.1179 - accuracy: 0.7010 - val_loss: 2.3809 - val_accuracy: 0.6062 - lr: 0.1000\n",
      "Epoch 14/20\n",
      "195/195 [==============================] - 14s 71ms/step - loss: 1.9572 - accuracy: 0.7273 - val_loss: 2.3158 - val_accuracy: 0.6060 - lr: 0.1000\n",
      "Epoch 15/20\n",
      "195/195 [==============================] - 14s 70ms/step - loss: 1.8523 - accuracy: 0.7418 - val_loss: 2.1816 - val_accuracy: 0.6380 - lr: 0.1000\n",
      "Epoch 16/20\n",
      "195/195 [==============================] - 14s 70ms/step - loss: 1.7158 - accuracy: 0.7660 - val_loss: 2.0981 - val_accuracy: 0.6445 - lr: 0.1000\n",
      "Epoch 17/20\n",
      "195/195 [==============================] - 14s 71ms/step - loss: 1.6337 - accuracy: 0.7730 - val_loss: 47.6724 - val_accuracy: 0.1415 - lr: 0.1000\n",
      "Epoch 18/20\n",
      "195/195 [==============================] - 14s 70ms/step - loss: 1.5839 - accuracy: 0.7718 - val_loss: 1.9877 - val_accuracy: 0.6527 - lr: 0.1000\n",
      "Epoch 19/20\n",
      "195/195 [==============================] - 14s 71ms/step - loss: 1.4367 - accuracy: 0.8071 - val_loss: 2.1152 - val_accuracy: 0.6296 - lr: 0.1000\n",
      "Epoch 20/20\n",
      "195/195 [==============================] - 14s 74ms/step - loss: 1.3366 - accuracy: 0.8262 - val_loss: 2.2660 - val_accuracy: 0.6061 - lr: 0.1000\n"
     ]
    }
   ],
   "source": [
    "resnet_34_cifar10.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum = 0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "histort_resnet_34_cifar10 = resnet_34_cifar10.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks = [reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plain_34_cifar10' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-37ebed597fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plain_34_cifar10.compile(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plain_34_cifar10' is not defined"
     ]
    }
   ],
   "source": [
    "plain_34_cifar10.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum = 0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "histort_plain_34_cifar10 = plain_34_cifar10.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks = [reduce_lr]\n",
    ")"
   ]
  },
  {
   "source": [
    "## cifar-10 에 대한 resnet-34, plain-34 훈련 결과 비교"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### training loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histort_resnet_34_cifar10.history['loss'], 'r')\n",
    "plt.plot(histort_plain_34_cifar10.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_34', 'plain_34'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### validation accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histort_resnet_34_cifar10.history['val_accuracy'], 'r')\n",
    "plt.plot(histort_plain_34_cifar10.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_34', 'plain_34'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### 결과\n",
    "\n",
    "~~resnet 이 loss 가 더 낮고, validation accuracy는 초반에 더 높다가 후반에 비슷하게 수렴한다.~~  \n",
    "논문에 제시된 내용을 추가로 반영하여 훈련시키니, 차이가 더 두드러지게 보인다.\n",
    "resnet이 plain에 비해 loss 와 validation accuracy가 모두 확연히 낮아짐을 볼 수 있음."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 50 으로 cifar-10 훈련"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "149/195 [=====================>........] - ETA: 11s - loss: 5.1813 - accuracy: 0.2604"
     ]
    },
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[256,256,8,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_1/block_0_1_bn_3/FusedBatchNormV3 (defined at <ipython-input-24-e2585e1a2d68>:15) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_203576]\n\nFunction call stack:\ntrain_function\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e2585e1a2d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[256,256,8,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_1/block_0_1_bn_3/FusedBatchNormV3 (defined at <ipython-input-24-e2585e1a2d68>:15) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_203576]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "resnet_50_cifar10.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum = 0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "histort_resnet_50_cifar10 = resnet_50_cifar10.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks = [reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_50_cifar10.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum = 0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "histort_plain_50_cifar10 = plain_50_cifar10.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks = [reduce_lr]\n",
    ")"
   ]
  },
  {
   "source": [
    "## cifar-10 에 대한 resnet-50, plain-50 훈련 결과 비교"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### training loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histort_resnet_50_cifar10.history['loss'], 'r')\n",
    "plt.plot(histort_plain_50_cifar10.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_50', 'plain_50'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### validation accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histort_resnet_50_cifar10.history['val_accuracy'], 'r')\n",
    "plt.plot(histort_plain_50_cifar10.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_50', 'plain_50'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### 결과\n",
    "\n",
    "~~34 와 마찬가지로, resnet이 loss 가 더 낮고, accuracy는 비슷하다.~~  \n",
    "34와 마찬가지로, 변경 사항을 적용했더니 resnet이 훨씬 나은 것이 보인다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## input_shape (224,224,3) 으로 비교해보기 : cats vs dogs 로 비교해보기\n",
    "\n",
    "batch_size = 256 으로는 동작이 멈춰서, 확 낮춰서 32 로 하니 되길래, 32로 진행함"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=1\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_cat_dog, ds_info_cat_dog = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "ds_cat_dog = ds_cat_dog[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 데이터셋을 로드하면 꼭 feature 정보를 확인해 보세요. \n",
    "print(ds_info_cat_dog.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = int(ds_info_cat_dog.splits['train'].num_examples*0.8)\n",
    "TEST_SIZE = int(ds_info_cat_dog.splits['train'].num_examples*0.2)\n",
    "\n",
    "ds_train_cat_dog = ds_cat_dog.take(TRAIN_SIZE)\n",
    "ds_test_cat_dog = ds_cat_dog.skip(TRAIN_SIZE)\n",
    "ds_test_cat_dog = ds_test_cat_dog.take(TEST_SIZE)\n",
    "\n",
    "# ds_cat_dog = pd.DataFrame(ds_cat_dog[0])\n",
    "# ds_cat_dog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msk = np.random.rand(ds_cat_dog.shape[0]) < 0.8\n",
    "# ds_train_cat_dog = ds_cat_dog[msk]\n",
    "# ds_test_cat_dog = ds_cat_dog[~msk]\n",
    "\n",
    "ds_train_cat_dog = apply_normalize_on_dataset(ds_train_cat_dog, batch_size=BATCH_SIZE)\n",
    "ds_test_cat_dog = apply_normalize_on_dataset(ds_test_cat_dog, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_cat_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_cat_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog_input_shape = (224, 224, 3)\n",
    "cat_dog_num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cats_vs_dogs 을 대상으로 하는 모델\n",
    "resnet_50_cat_dog = build_resnet(input_shape=cat_dog_input_shape,is_50 = True, num_classes=cat_dog_num_classes)\n",
    "resnet_50_cat_dog.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cats_vs_dogs 을 대상으로 하는 모델\n",
    "plain_50_cat_dog = build_plain(input_shape=cat_dog_input_shape,is_50 = True, num_classes=cat_dog_num_classes)\n",
    "plain_50_cat_dog.summary()"
   ]
  },
  {
   "source": [
    "### cifar10 데이터로는 34 로 해보았으니, 이번에는 50으로 해본다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50_cat_dog.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum = 0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "histort_resnet_50_cat_dog = resnet_50_cat_dog.fit(\n",
    "    ds_train_cat_dog,\n",
    "    steps_per_epoch=int(ds_info_cat_dog.splits['train'].num_examples*0.8/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info_cat_dog.splits['train'].num_examples*0.2/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test_cat_dog,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks = [reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_50_cat_dog.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum = 0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "histort_plain_50_cat_dog = plain_50_cat_dog.fit(\n",
    "    ds_train_cat_dog,\n",
    "    steps_per_epoch=int(ds_info_cat_dog.splits['train'].num_examples*0.8/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info_cat_dog.splits['train'].num_examples*0.2/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test_cat_dog,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks = [reduce_lr]\n",
    ")"
   ]
  },
  {
   "source": [
    "### training loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histort_resnet_50_cat_dog.history['loss'], 'r')\n",
    "plt.plot(histort_plain_50_cat_dog.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_50', 'plain_50'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### validation accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histort_resnet_50_cat_dog.history['val_accuracy'], 'r')\n",
    "plt.plot(histort_plain_50_cat_dog.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_50', 'plain_50'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### 비교 결과\n",
    "loss 는 비슷하게 수렴하였고\n",
    "accuracy는 둘 다 들쭉날쭉하였다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 결과 보고서"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "처음에 사용했던 cifar-10 데이터셋에 대해서는 resnet이 우월한 성능을 보여주었으나,   \n",
    "두 번째로 사용한 cats_vs_dogs 데이터셋에 대해서는 plain 네트워크와 resnet의 성능이 큰 차이가 없어보였으며, 오히려 plain 네트워크가 정확도 측면에서 살짝 더 좋은 결과를 보이는 듯한 결과를 보여주기도 하였다.\n",
    "모델 compile 혹은 훈련 과정에서 문제가 있었을 수도 있겠다는 생각이 든다.\n",
    "\n",
    "---\n",
    "### 10월 19일 추가 실험\n",
    "모델 구성 및 학습 요소에서 논문에 제시된 내용과 다르게 구성된 부분이 있었다. (weight decay , learning rate reduction)\n",
    "처음에 구현할 때는 어떻게 하는지 모르겠어서 제외하고 진행했던 내용이었는데, 포함시켜서 모델을 다시 만들고 학습시켜보았다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}